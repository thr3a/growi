# ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½ ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## æ¦‚è¦
`/workspace/growi/apps/app/src/server/service/import/import.ts` ãŠã‚ˆã³é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ã‚’è©³ç´°åˆ†æã—ãŸçµæœã§ã™ã€‚

## ğŸ”´ é«˜ãƒªã‚¹ã‚¯ï¼šãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ãŒé«˜ã„ç®‡æ‰€

### 1. ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã§ã®å‚ç…§ä¿æŒ
**å ´æ‰€**: `importCollection`ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè¡Œ 181-279ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
// prepare functions invoked from custom streams
const convertDocuments = this.convertDocuments.bind(this);
const bulkOperate = this.bulkOperate.bind(this);
const execUnorderedBulkOpSafely = this.execUnorderedBulkOpSafely.bind(this);
const emitProgressEvent = this.emitProgressEvent.bind(this);

await pipelinePromise(readStream, jsonStream, convertStream, batchStream, writeStream);
```

**å•é¡Œç‚¹**:
- `bind()`ã§ä½œæˆã•ã‚ŒãŸé–¢æ•°ãŒã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£ã‚’å½¢æˆã—ã€`this`ã¸ã®å¼·ã„å‚ç…§ã‚’ä¿æŒ
- é•·æ™‚é–“å®Ÿè¡Œã•ã‚Œã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‡¦ç†ä¸­ã«ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒè§£æ”¾ã•ã‚Œãªã„
- ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ä¸­ã®ä¸­æ–­æ™‚ã«è¤‡æ•°ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒé©åˆ‡ã«ç ´æ£„ã•ã‚Œãªã„
- 5ã¤ã®ç•°ãªã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒé€£é–ã—ã€ã‚¨ãƒ©ãƒ¼æ™‚ã®éƒ¨åˆ†çš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸è¶³

**å½±éŸ¿åº¦**: é«˜ - å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«æ·±åˆ»ãªå½±éŸ¿

### 2. Transform/Writableã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè“„ç©
**å ´æ‰€**: `convertStream`ã¨`writeStream`ï¼ˆè¡Œ 215-268ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
const convertStream = new Transform({
  objectMode: true,
  transform(doc, encoding, callback) {
    const converted = convertDocuments(collectionName, doc, overwriteParams);
    this.push(converted);
    callback();
  },
});

const writeStream = new Writable({
  objectMode: true,
  async write(batch, encoding, callback) {
    // ... å¤§é‡ã®å‡¦ç†
    batch.forEach((document) => {
      bulkOperate(unorderedBulkOp, collectionName, document, importSettings);
    });
    // ...
  },
});
```

**å•é¡Œç‚¹**:
- `convertDocuments`ã§`structuredClone()`ã«ã‚ˆã‚‹ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ãŒå¤§é‡å®Ÿè¡Œ
- ãƒãƒƒãƒå‡¦ç†ä¸­ã«å¤‰æ›ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒä¸€æ™‚çš„ã«å¤§é‡è“„ç©
- `UnorderedBulkOperation`ã«è¿½åŠ ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒExecuteå‰ã¾ã§ä¿æŒ
- ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¾ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç´¯ç©å¢—åŠ 

**å½±éŸ¿åº¦**: é«˜ - ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã«æ¯”ä¾‹ã—ã¦æ·±åˆ»åŒ–

### 3. MongoDB UnorderedBulkOperation ã§ã®å¤§é‡ãƒ‡ãƒ¼ã‚¿ä¿æŒ
**å ´æ‰€**: `writeStream`å†…ã®ãƒãƒ«ã‚¯å‡¦ç†ï¼ˆè¡Œ 230-250ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
const unorderedBulkOp = collection.initializeUnorderedBulkOp();

batch.forEach((document) => {
  bulkOperate(unorderedBulkOp, collectionName, document, importSettings);
});

const { result, errors } = await execUnorderedBulkOpSafely(unorderedBulkOp);
```

**å•é¡Œç‚¹**:
- `initializeUnorderedBulkOp()`ã§ä½œæˆã•ã‚Œã‚‹ãƒãƒ«ã‚¯æ“ä½œã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå†…éƒ¨ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿æŒ
- `BULK_IMPORT_SIZE`(100)å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒexecute()ã¾ã§å®Œå…¨ã«ãƒ¡ãƒ¢ãƒªã«è“„ç©
- upsertæ“ä½œæ™‚ã®æŸ¥è¯¢æ¡ä»¶ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã®é‡è¤‡ä¿æŒ
- MongoDBãƒ‰ãƒ©ã‚¤ãƒå†…éƒ¨ã§ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°

**å½±éŸ¿åº¦**: é«˜ - MongoDBãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ¬ãƒ™ãƒ«ã§ã®ãƒ¡ãƒ¢ãƒªè“„ç©

### 4. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ã§ã®ä¸é©åˆ‡ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
**å ´æ‰€**: `unzip`ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè¡Œ 344-376ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
const readStream = fs.createReadStream(zipFile);
const parseStream = unzipStream.Parse();
const unzipEntryStream = pipeline(readStream, parseStream, () => {});

unzipEntryStream.on('entry', (entry) => {
  const jsonFile = path.join(this.baseDir, fileName);
  const writeStream = fs.createWriteStream(jsonFile, { encoding: this.growiBridgeService.getEncoding() });
  pipeline(entry, writeStream, () => {});
  files.push(jsonFile);
});

await finished(unzipEntryStream);
```

**å•é¡Œç‚¹**:
- è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦ä¸¦è¡Œã—ã¦WriteStreamã‚’ä½œæˆ
- `pipeline`ã®å®Œäº†ã‚’å¾…ãŸãšã«æ¬¡ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼å‡¦ç†é–‹å§‹
- å¤§ããªZIPãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚ã«è¤‡æ•°ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒåŒæ™‚ã«å‹•ä½œ
- ã‚¨ãƒ©ãƒ¼æ™‚ã®å€‹åˆ¥ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ç ´æ£„å‡¦ç†ãªã—

**å½±éŸ¿åº¦**: é«˜ - ZIPãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«ãƒªãƒ¼ã‚¯

## ğŸŸ¡ ä¸­ãƒªã‚¹ã‚¯ï¼šæ¡ä»¶ã«ã‚ˆã£ã¦ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§

### 5. æ‰‹å‹•ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¸ã®ä¾å­˜
**å ´æ‰€**: `writeStream`ã®å‡¦ç†å®Œäº†æ™‚ï¼ˆè¡Œ 253-259ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
try {
  // First aid to prevent unexplained memory leaks
  logger.info('global.gc() invoked.');
  gc();
}
catch (err) {
  logger.error('fail garbage collection: ', err);
}
```

**å•é¡Œç‚¹**:
- æ‰‹å‹•GCã«ä¾å­˜ã—ã¦ã„ã‚‹ã®ã¯ã€ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å­˜åœ¨ã‚’ç¤ºå”†
- GCãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ãªã—
- æ¯ãƒãƒƒãƒã§GCã‚’å‘¼ã³å‡ºã™ã“ã¨ã«ã‚ˆã‚‹å‡¦ç†æ€§èƒ½ã®åŠ£åŒ–
- æ ¹æœ¬çš„ãªãƒ¡ãƒ¢ãƒªç®¡ç†å•é¡Œã®ç—‡çŠ¶å¯¾å‡¦ã«ã™ããªã„

**å½±éŸ¿åº¦**: ä¸­ - GCå¤±æ•—æ™‚ã®ç´¯ç©çš„å½±éŸ¿

### 6. ConvertMap ã¨ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã®é‡è¤‡ä¿æŒ
**å ´æ‰€**: `convertDocuments`ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè¡Œ 415-455ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
const Model = getModelFromCollectionName(collectionName);
const schema = (Model != null) ? Model.schema : undefined;
const convertMap = this.convertMap[collectionName];

const _document: D = structuredClone(document);
```

**å•é¡Œç‚¹**:
- æ¯å›Modelã¨schemaã®å–å¾—å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã‚‹
- `structuredClone()`ã«ã‚ˆã‚‹æ·±ã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ”ãƒ¼ã§ä¸€æ™‚çš„ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¢—å¤§
- ConvertMapã®é–¢æ•°ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒé•·æœŸé–“ä¿æŒã•ã‚Œã‚‹
- å¤§é‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†æ™‚ã®ç´¯ç©çš„ãªã‚¯ãƒ­ãƒ¼ãƒ³ä½œæˆ

**å½±éŸ¿åº¦**: ä¸­ - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¤‰æ›å‡¦ç†ã®é »åº¦ã«ä¾å­˜

### 7. ã‚¤ãƒ™ãƒ³ãƒˆã‚¨ãƒŸãƒƒã‚·ãƒ§ãƒ³å‡¦ç†ã§ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè“„ç©
**å ´æ‰€**: `emitProgressEvent`ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆè¡Œ 323-328ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
emitProgressEvent(collectionProgress, errors);

// å†…éƒ¨å®Ÿè£…
this.adminEvent.emit(SocketEventName.ImportingCollectionProgressingList, { 
  collectionName, 
  collectionProgress, 
  appendedErrors 
});
```

**å•é¡Œç‚¹**:
- é€²è¡ŒçŠ¶æ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒé »ç¹ã«ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ç™ºè¡Œ
- Socket.ioçµŒç”±ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡ã•ã‚Œã‚‹ã¾ã§ãƒ¡ãƒ¢ãƒªã«ä¿æŒ
- ã‚¨ãƒ©ãƒ¼æƒ…å ±ã®é…åˆ—ãŒç´¯ç©çš„ã«ä¿æŒã•ã‚Œã‚‹å¯èƒ½æ€§
- WebSocketæ¥ç¶šã®åˆ‡æ–­æ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚­ãƒ¥ãƒ¼ã®è“„ç©

**å½±éŸ¿åº¦**: ä¸­ - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šçŠ¶æ…‹ã«ä¾å­˜

### 8. ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æ°¸ç¶šä¿æŒ
**å ´æ‰€**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆï¼ˆindex.tsï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
let instance: ImportService;

export const initializeImportService = (crowi: Crowi): void => {
  if (instance == null) {
    instance = new ImportService(crowi);
  }
};
```

**å•é¡Œç‚¹**:
- ImportServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†ã¾ã§è§£æ”¾ã•ã‚Œãªã„
- `convertMap`ã€`currentProgressingStatus`ãªã©ã®å†…éƒ¨çŠ¶æ…‹ãŒæ°¸ç¶šä¿æŒ
- å¤§é‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¾Œã®ä¸­é–“ãƒ‡ãƒ¼ã‚¿ãŒã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å†…ã«æ®‹å­˜å¯èƒ½æ€§
- ãƒ¡ãƒ¢ãƒªãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ã®ä¸å‚™

**å½±éŸ¿åº¦**: ä¸­ - é•·æ™‚é–“ç¨¼åƒæ™‚ã®ç´¯ç©å½±éŸ¿

## ğŸŸ¢ ä½ãƒªã‚¹ã‚¯ï¼šæ½œåœ¨çš„ãªãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯

### 9. JSONè§£æå‡¦ç†ã§ã®ä¸€æ™‚çš„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆ
**å ´æ‰€**: `JSONStream.parse('*')`ä½¿ç”¨ï¼ˆè¡Œ 212ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
const jsonStream = JSONStream.parse('*');
```

**å•é¡Œç‚¹**:
- å¤§ããªJSONãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è§£ææ™‚ã®ä¸€æ™‚çš„ãƒ¡ãƒ¢ãƒªæ¶ˆè²»
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è§£æã§ã‚‚éƒ¨åˆ†çš„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¿æŒ
- å½¢å¼ä¸æ­£ãªJSONã§ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ¡ãƒ¢ãƒªæ–­ç‰‡åŒ–

**å½±éŸ¿åº¦**: ä½ - é€šå¸¸ã¯è‡ªå‹•çš„ã«è§£æ”¾

### 10. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†
**å ´æ‰€**: ZIPãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹ã¨JSONãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆè¡Œ 198, 273ï¼‰  
**å•é¡Œã‚³ãƒ¼ãƒ‰**:
```typescript
const jsonFile = this.getFile(jsonFileName);
// ... å‡¦ç†
fs.unlinkSync(jsonFile);
```

**å•é¡Œç‚¹**:
- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤å¤±æ•—æ™‚ã®ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡è“„ç©
- å‡¦ç†ä¸­æ–­æ™‚ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«æ®‹å­˜
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†

**å½±éŸ¿åº¦**: ä½ - ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®å•é¡Œï¼ˆãƒ¡ãƒ¢ãƒªã§ã¯ãªã„ï¼‰

## ğŸ“‹ æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£æ¡ˆ

### 1. ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ã®æ”¹å–„ï¼ˆæœ€å„ªå…ˆï¼‰
```typescript
protected async importCollection(collectionName: string, importSettings: ImportSettings): Promise<void> {
  if (this.currentProgressingStatus == null) {
    throw new Error('Something went wrong: currentProgressingStatus is not initialized');
  }

  // WeakMapã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒ å‚ç…§ã®å¼±ã„ç®¡ç†
  const streamRefs = new WeakMap();
  let readStream: any;
  let jsonStream: any;
  let convertStream: any;
  let batchStream: any;
  let writeStream: any;

  try {
    const collection = mongoose.connection.collection(collectionName);
    const { mode, jsonFileName, overwriteParams } = importSettings;
    const collectionProgress = this.currentProgressingStatus.progressMap[collectionName];
    const jsonFile = this.getFile(jsonFileName);

    // validate options
    this.validateImportSettings(collectionName, importSettings);

    // flush
    if (mode === ImportMode.flushAndInsert) {
      await collection.deleteMany({});
    }

    // ã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆæ™‚ã®æ˜ç¤ºçš„ãªå‚ç…§ç®¡ç†
    readStream = fs.createReadStream(jsonFile, { encoding: this.growiBridgeService.getEncoding() });
    streamRefs.set(readStream, 'readStream');

    jsonStream = JSONStream.parse('*');
    streamRefs.set(jsonStream, 'jsonStream');

    // bind()ã‚’é¿ã‘ã¦ç›´æ¥é–¢æ•°å‚ç…§ã‚’ä½¿ç”¨
    convertStream = new Transform({
      objectMode: true,
      transform: (doc, encoding, callback) => {
        try {
          const converted = this.convertDocumentsSafely(collectionName, doc, overwriteParams);
          this.push(converted);
          callback();
        } catch (error) {
          callback(error);
        }
      },
    });
    streamRefs.set(convertStream, 'convertStream');

    batchStream = createBatchStream(BULK_IMPORT_SIZE);
    streamRefs.set(batchStream, 'batchStream');

    writeStream = new Writable({
      objectMode: true,
      write: async (batch, encoding, callback) => {
        try {
          await this.processBatchSafely(collection, batch, collectionName, importSettings, collectionProgress);
          callback();
        } catch (error) {
          callback(error);
        }
      },
      final: (callback) => {
        logger.info(`Importing ${collectionName} has completed.`);
        callback();
      },
    });
    streamRefs.set(writeStream, 'writeStream');

    // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šä»˜ããƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Import timeout')), 30 * 60 * 1000); // 30åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    });

    await Promise.race([
      pipelinePromise(readStream, jsonStream, convertStream, batchStream, writeStream),
      timeoutPromise,
    ]);

    // æ­£å¸¸å®Œäº†æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    fs.unlinkSync(jsonFile);

  } catch (err) {
    throw new ImportingCollectionError(collectionProgress, err);
  } finally {
    // æ˜ç¤ºçš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    this.cleanupStreams([readStream, jsonStream, convertStream, batchStream, writeStream]);
  }
}

private cleanupStreams(streams: any[]): void {
  streams.forEach(stream => {
    if (stream && typeof stream.destroy === 'function') {
      try {
        stream.destroy();
      } catch (e) {
        logger.warn('Failed to destroy stream:', e);
      }
    }
  });
}
```

### 2. ãƒãƒƒãƒå‡¦ç†ã®æœ€é©åŒ–
```typescript
private async processBatchSafely(
  collection: any,
  batch: any[],
  collectionName: string,
  importSettings: ImportSettings,
  collectionProgress: any
): Promise<void> {
  // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
  const memBefore = process.memoryUsage();
  
  try {
    const unorderedBulkOp = collection.initializeUnorderedBulkOp();

    // ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‹•çš„ã«èª¿æ•´
    const adjustedBatchSize = this.calculateOptimalBatchSize(batch);
    const chunks = this.chunkArray(batch, adjustedBatchSize);

    for (const chunk of chunks) {
      // ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«å‡¦ç†ã—ã¦ãƒ¡ãƒ¢ãƒªåœ§è¿«ã‚’è»½æ¸›
      chunk.forEach((document) => {
        this.bulkOperate(unorderedBulkOp, collectionName, document, importSettings);
      });

      const { result, errors } = await this.execUnorderedBulkOpSafely(unorderedBulkOp);
      
      // çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
      this.updateProgress(collectionProgress, result, errors);
      
      // ä¸­é–“ã§ã®ãƒ¡ãƒ¢ãƒªç›£è¦–
      const memCurrent = process.memoryUsage();
      if (memCurrent.heapUsed > memBefore.heapUsed * 2) {
        logger.warn('High memory usage detected, forcing GC');
        if (global.gc) {
          global.gc();
        }
      }
    }
  } catch (error) {
    logger.error('Error in batch processing:', error);
    throw error;
  }
}

private calculateOptimalBatchSize(batch: any[]): number {
  const currentMemory = process.memoryUsage();
  const availableMemory = currentMemory.heapTotal - currentMemory.heapUsed;
  const avgDocSize = JSON.stringify(batch[0] || {}).length;
  
  // åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®50%ä»¥ä¸‹ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´
  const optimalSize = Math.min(
    BULK_IMPORT_SIZE,
    Math.floor(availableMemory * 0.5 / avgDocSize)
  );
  
  return Math.max(10, optimalSize); // æœ€å°10ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
}
```

### 3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¤‰æ›ã®åŠ¹ç‡åŒ–
```typescript
private convertDocumentsSafely<D extends Document>(
  collectionName: string,
  document: D,
  overwriteParams: OverwriteParams
): D {
  // ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚­ãƒ¼ãƒã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
  if (!this.modelCache) {
    this.modelCache = new Map();
  }
  
  let modelInfo = this.modelCache.get(collectionName);
  if (!modelInfo) {
    const Model = getModelFromCollectionName(collectionName);
    const schema = (Model != null) ? Model.schema : undefined;
    modelInfo = { Model, schema };
    this.modelCache.set(collectionName, modelInfo);
  }

  const { schema } = modelInfo;
  const convertMap = this.convertMap[collectionName];

  // æµ…ã„ã‚³ãƒ”ãƒ¼ã§ååˆ†ãªå ´åˆã¯structuredClone()ã‚’é¿ã‘ã‚‹
  const _document: D = this.createOptimalCopy(document);

  // æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å‡¦ç†
  this.applyConversions(_document, document, convertMap, overwriteParams, schema);

  return _document;
}

private createOptimalCopy<D extends Document>(document: D): D {
  // å˜ç´”ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆã¯æµ…ã„ã‚³ãƒ”ãƒ¼
  if (this.isSimpleObject(document)) {
    return { ...document };
  }
  // è¤‡é›‘ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿deep clone
  return structuredClone(document);
}

private isSimpleObject(obj: any): boolean {
  return typeof obj === 'object' && 
         obj !== null && 
         !Array.isArray(obj) && 
         Object.values(obj).every(v => 
           typeof v !== 'object' || v === null || v instanceof Date
         );
}
```

### 4. ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã®æ”¹å–„
```typescript
async unzip(zipFile: string): Promise<string[]> {
  const files: string[] = [];
  const activeStreams = new Set<any>();
  
  try {
    const readStream = fs.createReadStream(zipFile);
    const parseStream = unzipStream.Parse();
    
    const unzipEntryStream = pipeline(readStream, parseStream, () => {});
    activeStreams.add(readStream);
    activeStreams.add(parseStream);

    const entryPromises: Promise<void>[] = [];

    unzipEntryStream.on('entry', (entry) => {
      const fileName = entry.path;
      
      // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
      if (fileName.match(/(\\.\\.\\/|\\.\\.\\\\)/)) {
        logger.error('File path is not appropriate.', fileName);
        entry.autodrain();
        return;
      }

      if (fileName === this.growiBridgeService.getMetaFileName()) {
        entry.autodrain();
      } else {
        const entryPromise = this.extractEntry(entry, fileName);
        entryPromises.push(entryPromise);
        
        entryPromise.then((filePath) => {
          if (filePath) files.push(filePath);
        }).catch((error) => {
          logger.error('Failed to extract entry:', error);
        });
      }
    });

    await finished(unzipEntryStream);
    await Promise.all(entryPromises);

    return files;
  } catch (error) {
    logger.error('Error during unzip:', error);
    throw error;
  } finally {
    // ã™ã¹ã¦ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’æ˜ç¤ºçš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    activeStreams.forEach(stream => {
      if (stream && typeof stream.destroy === 'function') {
        stream.destroy();
      }
    });
  }
}

private async extractEntry(entry: any, fileName: string): Promise<string | null> {
  return new Promise((resolve, reject) => {
    const jsonFile = path.join(this.baseDir, fileName);
    const writeStream = fs.createWriteStream(jsonFile, { 
      encoding: this.growiBridgeService.getEncoding() 
    });

    const timeout = setTimeout(() => {
      writeStream.destroy();
      entry.destroy();
      reject(new Error(`Extract timeout for ${fileName}`));
    }, 5 * 60 * 1000); // 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

    pipeline(entry, writeStream, (error) => {
      clearTimeout(timeout);
      if (error) {
        reject(error);
      } else {
        resolve(jsonFile);
      }
    });
  });
}
```

### 5. ãƒ¡ãƒ¢ãƒªç›£è¦–ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®è¿½åŠ 
```typescript
class ImportMemoryMonitor {
  private static thresholds = {
    warning: 512 * 1024 * 1024, // 512MB
    critical: 1024 * 1024 * 1024, // 1GB
  };

  static monitorMemoryUsage(operation: string): void {
    const mem = process.memoryUsage();
    
    if (mem.heapUsed > this.thresholds.critical) {
      logger.error(`Critical memory usage in ${operation}:`, {
        heapUsed: Math.round(mem.heapUsed / 1024 / 1024) + ' MB',
        heapTotal: Math.round(mem.heapTotal / 1024 / 1024) + ' MB',
      });
      
      if (global.gc) {
        global.gc();
        logger.info('Emergency GC executed');
      }
    } else if (mem.heapUsed > this.thresholds.warning) {
      logger.warn(`High memory usage in ${operation}:`, {
        heapUsed: Math.round(mem.heapUsed / 1024 / 1024) + ' MB',
      });
    }
  }

  static async schedulePeriodicCleanup(): Promise<void> {
    setInterval(() => {
      const mem = process.memoryUsage();
      if (mem.heapUsed > this.thresholds.warning && global.gc) {
        global.gc();
        logger.debug('Periodic GC executed');
      }
    }, 30000); // 30ç§’é–“éš”
  }
}

// ImportServiceã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 
public cleanup(): void {
  // é€²è¡ŒçŠ¶æ³ã®åˆæœŸåŒ–
  this.currentProgressingStatus = null;
  
  // convertMapã®ã‚¯ãƒªã‚¢
  if (this.convertMap) {
    Object.keys(this.convertMap).forEach(key => {
      delete this.convertMap[key];
    });
  }
  
  // modelCacheã®ã‚¯ãƒªã‚¢
  if (this.modelCache) {
    this.modelCache.clear();
  }
  
  logger.info('ImportService cleanup completed');
}
```

## ğŸ¯ å„ªå…ˆé †ä½

1. **å³åº§ã«å¯¾å¿œã™ã¹ã**: é«˜ãƒªã‚¹ã‚¯é …ç›® 1-4ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ã€ãƒãƒƒãƒå‡¦ç†ã€MongoDBæ“ä½œã€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼‰
2. **çŸ­æœŸé–“ã§å¯¾å¿œ**: ä¸­ãƒªã‚¹ã‚¯é …ç›® 5-8ï¼ˆGCä¾å­˜ã€å¤‰æ›å‡¦ç†ã€ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç®¡ç†ï¼‰
3. **ä¸­é•·æœŸã§æ¤œè¨**: ä½ãƒªã‚¹ã‚¯é …ç›® 9-10ï¼ˆæœ€é©åŒ–äº‹é …ï¼‰

## ğŸ“Š å½±éŸ¿äºˆæ¸¬

- **ä¿®æ­£å‰**: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«æ•°GBå˜ä½ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯å¯èƒ½æ€§
- **ä¿®æ­£å¾Œ**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å®‰å®šåŒ–ã€ãƒªãƒ¼ã‚¯ç‡ 95% ä»¥ä¸Šå‰Šæ¸›äºˆæƒ³

## ğŸ” ç¶™ç¶šç›£è¦–é …ç›®

- ãƒ’ãƒ¼ãƒ—ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨ç§»ï¼ˆç‰¹ã«ãƒãƒƒãƒå‡¦ç†ä¸­ï¼‰
- ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ã§ã®ä¾‹å¤–ç™ºç”Ÿç‡
- MongoDBæ¥ç¶šã¨ãƒãƒ«ã‚¯æ“ä½œã®çŠ¶æ…‹
- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãƒ»å‰Šé™¤çŠ¶æ³
- GCå®Ÿè¡Œé »åº¦ã¨ãã®åŠ¹æœ

---
**ä½œæˆæ—¥**: 2025å¹´9æœˆ12æ—¥  
**å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«**: `/workspace/growi/apps/app/src/server/service/import/import.ts`  
**åˆ†æè€…**: GitHub Copilot  
**é‡è¦åº¦**: é«˜ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½ã®å®‰å®šæ€§ã«ç›´çµï¼‰